{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image Classifier Project\n",
                "\n",
                "The dataset is comprised of photos of dogs and cats provided as a subset of photos from a much larger dataset of 3 million manually annotated photos. The dataset was developed as a partnership between Petfinder.com and Microsoft.\n",
                "\n",
                "The dataset was originally used as a CAPTCHA, that is, a task that it is believed a human finds trivial, but cannot be solved by a machine, used on websites to distinguish between human users and bots. The task was referred to as \"Asirra\". When \"Asirra\" was presented, it was mentioned 'that user studies indicate it can be solved by humans 99.6% of the time in under 30 seconds. Barring a major advance in machine vision, we expect computers will have no better than a 1/54,000 chance of solving it'.\n",
                "\n",
                "At the time that the competition was posted, the state-of-the-art result was achieved with an SVM and described in a 2007 paper with the title “Machine Learning Attacks Against the Asirra CAPTCHA” (PDF) that achieved 80% classification accuracy. It was this paper that demonstrated that the task was no longer a suitable task for a CAPTCHA soon after the task was proposed.\n",
                "\n",
                "The dataset is straightforward to understand and small enough to fit into memory and get started with computer vision and convolutional neural networks."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 1:**\n",
                "Download the datatset folder and unzip files"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 2:** Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import keras,os\n",
                "from keras.models import Sequential  #as all the layers of the model will be arranged in sequence\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "from keras.preprocessing.image import ImageDataGenerator # as it imports data with labels easily into the model. It has functions to rescale, rotate, zoom, etc. This class alters the data on the go while passing it to the model.\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 3:**\n",
                "\n",
                "Load and plot the first nine photos of dogs in a single figure. Repeat the same for cats. \n",
                "</br> Load the images progressively using the Keras ImageDataGenerator class and flow_from_directory() API."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 37500 images belonging to 2 classes.\n",
                        "Found 37500 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "trdata = ImageDataGenerator()\n",
                "traindata = trdata.flow_from_directory(directory=\"../data/raw\",target_size=(224,224))\n",
                "tsdata = ImageDataGenerator()\n",
                "testdata = tsdata.flow_from_directory(directory=\"../data/raw\", target_size=(224,224))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 4:**\n",
                "\n",
                "Create an object of ImageDataGenerator for both training and testing data and pass the folder which has train data to the object trdata and similarly pass the folder which has test data to the object tsdata."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 5:**\n",
                "\n",
                "Initialize the model by specifying that the model is a sequential model. After initialising the model add:\n",
                "\n",
                "→ 2 x convolution layer of 64 channel of 3x3 kernal and same padding\n",
                "\n",
                "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
                "\n",
                "→ 2 x convolution layer of 128 channel of 3x3 kernal and same padding\n",
                "\n",
                "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
                "\n",
                "→ 3 x convolution layer of 256 channel of 3x3 kernal and same padding\n",
                "\n",
                "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
                "\n",
                "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
                "\n",
                "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
                "\n",
                "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
                "\n",
                "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
                "\n",
                "Add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 6:**\n",
                "\n",
                "After creating all the convolution, pass the data to the dense layer. In order to do that, you should first flatten the vector which comes out of the convolutions and then add:\n",
                "\n",
                "→ 1 x Dense layer of 4096 units\n",
                "\n",
                "→ 1 x Dense layer of 4096 units\n",
                "\n",
                "→ 1 x Dense Softmax layer of 2 units\n",
                "\n",
                "Use RELU activation for both of the dense layers in order to stop forwarding negative values through the network. Use a 2 unit dense layer in the end with softmax activation as you have 2 classes to predict. The softmax layer will output the value between 0 and 1 based on the confidence of the model that which class the images belongs to."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 7:**\n",
                "\n",
                "Import Adam optimizer and use it to compile the model. Specify a learning rate for it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 8:**\n",
                "\n",
                "Check the summary of the model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 9:**\n",
                "\n",
                "Import ModelCheckpoint and EarlyStopping method from keras. Create an object of both and pass that as callback functions to fit_generator."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 10:**\n",
                "\n",
                "Once you have trained the model, visualise training/validation accuracy and loss."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 11:**\n",
                "\n",
                "Load the best saved model and pre-process the image, then pass the image to the model and make predictions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.5 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.5"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "be55531a80018631fb0dfb010073b3ec3c01ba5a90935dd3ed6089ae93a8f0c8"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
